events {
  process_date = "20200918"

  users_input = "/tmp/events/data/users"
  events_input = "/tmp/events/data/events"
  train_input = "/tmp/events/data/train"

  output_dir = "/tmp/events/features"
}

kafka {
  bootstrap.servers = "localhost:9092"
  schema.registry.url = "http://localhost:8081"
}

application {
  # Decryption key for test encrypted values - same as application-test.conf
  security.decryption.key = ${?DECRYPTION_KEY}

  scripts_uri = "/tmp/events/scripts"
  process_date = "2021-02-06"

  runtime {
    spark {
      app.name = "spark-etl-onprem"
      master = "local[*]"
    }

    hadoopConfiguration {
      mapreduce.fileoutputcommitter.marksuccessfuljobs = false
    }

    filesystem.skip.write.checksum = true
    hiveSupport = false
    validationRun = false
  }
}
