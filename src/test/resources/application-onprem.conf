events {
  process_date = "20200918"

  users_input = "src/test/resources/data/users"
  delta_output = "/tmp/delta/users_onprem"
  staging_uri = "/tmp/staging/events"

  db.password = ${?DB_PASSWORD}
  flight.password = ${?FLIGHT_PASSWORD}
}

application {
  security.decryption.key = ${?DECRYPTION_KEY}

  scripts_uri = "./scripts"
  process_date = "2021-02-06"

  runtime {
    spark {
      app.name = "spark-etl-onprem"
      master = "local[*]"
    }

    hadoopConfiguration {
      mapreduce.fileoutputcommitter.marksuccessfuljobs = false
    }

    filesystem.skip.write.checksum = true
    hiveSupport = true
    validationRun = false
  }
}
